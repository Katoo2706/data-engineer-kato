---
layout: default
icon: fas fa-info-circle
order: 4
---

## **Hi, I am a Data Engineer ðŸš€**

## Skills
> *"A reflection on my past accomplishments and experiments."*

<div style="display: flex; flex-wrap: wrap; gap: 20px;">

  <div style="flex: 1;">

    <details>
      <summary><strong>Language</strong></summary>
      <ul>
        <li><strong>Python: </strong> PySpark, Pandas / <strong>Polars</strong> (Robust single node data processing), Django / Flask (Backend system), Streamlit, Web scrap</li>
        <li><strong>Scala:</strong> Spark, Spark Streaming</li>
        <li>Advanced SQL</li>
      </ul>
    </details>

    <details>
      <summary><strong>Database</strong></summary>
      <ul>
        <li>Relational Database (MySQL, <strong>PostgreSQL</strong>)</li>
        <li>No structured Database (<strong>MongoDB</strong>, Cassandra, Redis)</li>
      </ul>
    </details>

    <details>
      <summary><strong>Data Visualization</strong></summary>
      <ul>
        <li>Enterprise: Microsoft Power BI</li>
        <li>Open-source: Superset, Metabase, Grafana, Plotly, Matplotlib (Experienced with server configuration & BI Dashboard embedding)</li>
      </ul>
    </details>

    <details>
      <summary><strong>Data Processing</strong></summary>
      <ul>
        <li><strong>Apache Airflow</strong> (Ochestration), Airbyte (Data ingestion layer), DBT (Data Builder Tool) (Transformation layer)</li>
        <li><strong>Spark, Spark Streaming (Scala)</strong> - Distributed data processing</li>
        <li><strong>Flask backend API</strong>: Data-driven Application, Streamlit: Data product</li>
        <li>Enterprise: Azure Data Factory, Databricks flow (Microsoft Azure)</li>
      </ul>
    </details>
    
    <details>
      <summary><strong>Data Warehouse</strong></summary>
      <ul>
        <li><strong>ClickHouse</strong> (columnar data warehouse)</li>
        <li><strong>Hive Metastore on Databricks</strong></li>
        <li><strong>Delta Lake</strong> (Lake house architecture)</li>
      </ul>
    </details>


  </div>

  <div style="flex: 1;">

    <details>
      <summary><strong>Data Lake â€“ Object Storage</strong></summary>
      <ul>
        <li>Enterprise: <strong>Google Cloud Storage, Microsoft Azure Data Lake Storage</strong></li>
        <li>Open-source: MinIO</li>
      </ul>
    </details>

    <details>
      <summary><strong>Cloud Service</strong></summary>
      <ul>
        <li><strong>Microsoft Azure</strong> (DataBricks, Azure Data Lake, Azure Data Warehouse)</li>
        <li>AWS Cloud (EC2, RDS, S3)</li>
        <li><strong>Google Cloud</strong> (Google Cloud Storage, Google Big Query, Google Kubernetes Engine, Google Sheet API, Google Drive API) â€“ Docker</li>
        <li>Hosting: Cloudflare</li>
      </ul>
    </details>

    <details>
      <summary><strong>Data Quality</strong></summary>
      <ul>
        <li>Great Expectation (dbt_expectation)</li>
      </ul>
    </details>

    <details>
      <summary><strong>Data Catalog</strong></summary>
      <ul>
        <li>dbdocs, dbdiagrams</li>
        <li>dbt documents sever</li>
        <li>Datahub</li>
      </ul>
    </details>

  </div>

</div>

-------
## My Journey

#### <kbd><strong>Data Analytics & Engineering Mentor </strong></kbd> - FUNiX Technologies School | `Jul 2023` - `Now`
- Empowered Future Data Professionals: Mentored at FUNiX School, providing practical guidance in data analytics and engineering.
- Curriculum Innovation: Enhanced curriculum with industry insights, ensuring students are job-ready in evolving data landscapes.

#### <kbd><strong>Data Engineer</strong></kbd> - Advesa Digital & Breadstack Technologies Company | `Oct 2022` - `Now`
- **Scope of works:** Data Engineer, Data Architecture & Operations.
- **Responsibilities:**
  - Build data warehouse system + Data Operations, Data Applications, ETL & ELT pipelines, and software integration with analytics dashboard.

1. **Design and manage all data architecture for these projects:**
    - Ecommerce & Marketing analytics project: RDBMS, ETL (Apache Airflow), rest API framework, Power BI
    - HR project: RDBMS, MongoDB, Streamlit - Mongo Atlas, ETL (Apache Airflow), Object Storage (MinIO)
    - Analytical Dashboard project: Clickhouse, redis, Apache Airflow, Postgres, ETL server (Flask rest API), Open-source analytics server + embedding architecture (Config infrastructure on Google Cloud with Helm chart + Kubernetes)
2. **Data sources integrations:**
    - Google Analytics, CRM, ERP system, Klaviyo, Social Platforms (Facebook / Instagram / Twitter / Linkedin), Companyâ€™s CRM softwares (Breadstack, Chatso), Task management (Jira, Trello)

**Technology usages:** ClickHouse Â· Apache Superset Â· Data Warehousing Â· Data Engineering Â· Mongo Atlas Â· MinIO Â· SQL Â· Streamlit Â· Python (Programming Language) Â· Data Modeling Â· Apache Airflow Â· PostgreSQL Â· MongoDB

#### <kbd><strong>ALM Specialist</strong></kbd> - TPBank | `Jan 2022` - `Oct 2022`
- **Responsibility:**
  - Build Python module to auto-cleanse data, build reports, and ETL data automatically
  - ALCO report / GAP report.
  - Daily FTP data management.
  - Coordinating implementation of liquidity management, optimizing cash flow on the balance sheet scale.
  - Make management reports as required and assigned.
  - Build automatic EDA with Python engine, transform old report to BI visualization,
  - Model to predict the CASA ratio, and pre-payment ratio.

**Technology usages:** Python Â· PowerBI Â· SQL Â· Qlikview

#### <kbd><strong>Data Analyst</strong></kbd> - Hong Ngoc Group | `Apr 2020` - `May 2022`
- **Responsibility:**
  - Manage Servicesâ€™ cost components, Servicesâ€™ pricing.
  - Work with BE team to improve the data system.
  - Building report dashboard, make ad-hoc by MS. Excel & Power BI
  - Cleansing data & Analyze Revenue, Profit, ROS and KPI of branches.
  - Improve and build the whole new Report dashboard, and improve data processing method of the team.

-------
## Certification

> *"For me, certificates are not an end in themselves. As far as I am concerned, it's about the progress to achieve all of that."*

> **IBM Data Engineering Professional Certificate** &nbsp; <a href="https://www.credly.com/badges/1ec2274c-8c05-411a-94e0-e0e20927e5f2/" target="_blank"> <img src="..%2Fassets%2Fpost%2Fcredly.png" alt="Certification Icon" style="height: 20px;"> </a>

> <a href="https://www.linkedin.com/in/katoo2706/details/certifications/" target="_blank"> <img src="..%2Fassets%2Fimg%2Flogo%2Flinkedin.png" alt="Certification Icon" style="height: 18px;"> </a>
